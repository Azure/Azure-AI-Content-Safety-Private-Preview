

#  Content Safety Private Preview Documentation  ![informational](https://shields.io/badge/-PrivatePreview-PrivatePreview) 


##  ðŸ“’ Overview 

This documentation site is structured into the following sections.

-  [**Multimodal API Documentation**](https://github.com/Azure/Azure-AI-Content-Safety-Private-Preview/blob/main/Multimodal%20API%20Private%20Preview.md) shares the latest update on performing content moderation on multi-modal content.
- [**Annotation API Documentation**](https://github.com/Azure/Azure-AI-Content-Safety-Private-Preview/blob/main/Annotation%20API%20Private%20Preview.md) introduces a new capability to perform adapted annotation on harmful content according to specific guidelines.
- [**Ungroundedness (Hallucination) Detection API**](https://github.com/Azure/Azure-AI-Content-Safety-Private-Preview/blob/main/Ungroundness%20Detection%20API%20Private%20Preview.md) detects ungroundedness generated by the large language models (LLMs). Ungroundedness refers to instances where the LLMs produce information that is non-factual or inaccurate from what was present in the source materials provided by the users.

##  ðŸ’¬ We're here to help!

If you get stuck, [shoot us an email](mailto:acm-team@microsoft.com) or use the feedback widget on the upper right of any page.
We're excited you're here! 
