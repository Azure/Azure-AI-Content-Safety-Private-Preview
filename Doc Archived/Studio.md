# Azure Conten Safety Studio

[Azure Content Safet Studio](https://contentsafety.cognitive.azure.com/text) is an online tool that uses cutting-edge content moderation ML models across multilingual, multimodal data to handle content that is potentially offensive, risky, or otherwise undesirable automatically, by easily setting up the moderation flow and continuously monitor and improve the performance. This studio provides a DETECT & MONITOR experience for content moderation requirements from all kinds of verticals like Gaming, Media, Education, E-commerce and more. Those verticals could easily connect their service to our studio and get content moderated in real time by posting an API every time a content coming in, no matter user generated content or AI generated content. 

## Prerequisites for new users
* An active [Azure account](https://azure.microsoft.com/free/cognitive-services/). If you don't have one, you can [create a free account](https://azure.microsoft.com/free/).
* A [Content Safety](https://aka.ms/acs-create) resource.

## Content Safety features

In Content Safety Studio, the following Content Safety service features are available:

* [Moderate Text Content](https://contentsafety.cognitive.azure.com/text):  With text moderation tool, you can easily run tests on text contents. Whether you want to test a simple sentence or an entire dataset, our tool offers a user-friendly interface that enables you to assess the test results directly in the portal. You can experiment with different sensitivity levels to configure your content filters and blocklist management, ensuring that your content is always moderated to your exact specifications. Plus, with the ability to export the code, you can implement the tool directly on your end, streamlining your workflow and saving time.

* [Moderate Image Content](https://contentsafety.cognitive.azure.com/image): With image moderation tool, you can easily run tests on images to ensure that they meet your content standards. Our user-friendly interface allows you to evaluate the test results directly in the portal, and you can experiment with different sensitivity levels to configure your content filters. Once you've customized your settings, you can easily export the code to implement the tool on your end.

* [Monitor Online Activity](https://contentsafety.cognitive.azure.com/monitor): powerful monitoring page feature that allows you to easily track your moderation API usage and trends across different modalities. With this feature, you can access detailed response information, including category and risk level distribution, latency, error, and blocklist detection. This information provides you with a complete overview of your content moderation performance, enabling you to optimize your workflow and ensure that your content is always moderated to your exact specifications. Plus, with our user-friendly interface, you can quickly and easily navigate the monitoring page to access the information you need to make informed decisions about your content moderation strategy. With our monitoring page feature, you'll have the tools you need to stay on top of your content moderation performance and achieve your content goals.

* [Build a Custom Solution](https://contentsafety.cognitive.azure.com/custom-solution) *(coming soon)*: Our comprehensive content moderation solution provides a complete set of tools to help you manage your projects and policies, streamline your dataset management, conduct experiments, deploy your models, and monitor your performance per policy. With our all-in-one solution, you'll have everything you need to manage your content moderation workflow efficiently and effectively. Our solution is designed to help you optimize your content moderation strategy, improve your team's productivity, and ensure that your content is always moderated to your exact specifications. Plus, with our user-friendly interface and intuitive features, you can easily navigate the platform and access the information you need to make informed decisions about your content moderation strategy.

* [Moderate Multi-modal Content](https://contentsafety.cognitive.azure.com/multi-modal) *(coming soon)*: We will be launching a new multi-modal capability for **Image + Text** moderation soon. This feature will be especially useful for moderating memes in social media, gaming, and other industries where image and text are often combined. We will be starting with a private preview of this feature. If you're interested in trying it out, please sign up using the link provided: [Sign up for Multi-modal preview](https://aka.ms/acsmultimodal), and we will notify you by email once you've been whitelisted. 

## Next steps

Get started with [Azure Content Safety Studio](https://contentsafety.cognitive.azure.com/text).
